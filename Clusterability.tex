\documentclass[11pt]{article}


%%%%% Packages %%%%%
\usepackage[paper]{nickstyle}
\usepackage{color}
\usepackage{hyperref}
\usepackage{amssymb, amsmath}



%%%%% Macros %%%%%
\setlength{\parindent}{24pt}
\renewcommand{\bar}[1]{\overline{#1}}

\newtheorem{fact}[theorem]{Fact}
\newtheorem{conj}[theorem]{Conjecture}
\newtheorem{problem}[theorem]{Problem}
\newcommand{\ConjName}[1]{\label{con:#1}}
\newcommand{\Conj}[1]{Conjecture~\ref{con:#1}}
\newcommand{\ProblemName}[1]{\label{prob:#1}}
\newcommand{\Problem}[1]{Problem~\ref{prob:#1}}
\renewcommand{\dot}{\bullet}
\newcommand{\Tr}{\operatorname{tr}}
\newcommand{\eps}{\epsilon}

\newcommand{\lmax}{\lambda_\mathrm{max}}
\newcommand{\lmin}{\lambda_\mathrm{min}}
\newcommand{\ufinal}{u_\mathrm{final}}
\newcommand{\lfinal}{l_\mathrm{final}}
\newcommand{\umax}{u_\mathrm{max}}

\newcommand{\Symraw}{\mathbb{S}}
\newcommand{\Sym}[1][]{\Symraw^{\ifthenelse{\equal{#1}{}}{m}{#1}}}
\newcommand{\Psd}[1][]{\Symraw_+^{\ifthenelse{\equal{#1}{}}{m}{#1}}}
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\iprod}[2]{\langle #1, #2 \rangle}
\newcommand{\paren}[2][]{#1({#2}#1)}
\newcommand{\qform}[2]{\transp{#2}#1#2}
\newcommand{\transp}[1]{#1^T}



% Simple (outer) environment for algorithms
\newenvironment{outer_alg}{
    \begin{list}{}{
        \setlength{\itemsep}{2pt}
        \setlength{\parsep}{0pt}
        \setlength{\parskip}{0pt}
        \setlength{\topsep}{1pt}
        \setlength{\leftmargin}{5pt}
    }
}
{
    \end{list}
}

% Simple environments for algorithms
\newenvironment{alg}{
    \begin{list}{}{
        \setlength{\itemsep}{2pt}
        \setlength{\parsep}{0pt}
        \setlength{\parskip}{0pt}
        \setlength{\topsep}{1pt}
    }
}
{
    \end{list}
}




%%%%% Title %%%%%
\title{\LARGE Noise robust clustering}
\author{}


%%%%% Document Body %%%%%
\begin{document}
\maketitle

\section{Introduction}
\begin{itemize}
\item Nika and Shai ICML'14
\end{itemize}

\section{Problem Statement}

\subsection{Notation}
For any set $B\subset X$, we denote $c(B)$ as the center of $B$ which is defined as the average of points in $B$. Radius of the set $B$ is defined as $r(B)=\max_{x\in B} |x-c(B)|$. Define the induced clustering.

\begin{definition}[Niceness assumption]
% Adding C_{k+1} as garbage collector?
Given a set $\mathcal{X}$, we say that $\mathcal{X}$ is $(\lambda,\nu)$-nice if there exist a partitioning of $\mathcal{X}$, $P=\{P_1,\ldots,P_k\}$ which satisfies the following conditions. There exist sets $B=\{B_1,\ldots,B_k\}\subset \mathcal{X}$ such that for every $i\in[k]$, there exists $j_i\in[k]$ such that $B_i\subset P_{j_i}$ and
\begin{itemize}
\item{\bf{Separation}:} For all $i,j\in[k], |c(B_i)-c(B_j)|\geq \nu\cdot\max\{r(B_i),r(B_j)\}$
\item{\bf{Sparse Noise}}: For any ball $B\subset \mathcal{X}$, if $r(B)\leq \lambda \cdot \max_{i\in[k]} r(B_i)$, then $|B\cap \{X \backslash \cup_{i\in[k]} B_i\}| < \min_{i\in[k]}|B_i|$.
\end{itemize}
\end{definition}


\noindent {\bf Goal}: Given the set $\mathcal{X}$ and the value $k$, our goal is to design an algorithm that does $k$-clustering $C=\{C_1,\ldots,C_k\}$ on set $\mathcal{X}$ such that  for any $(\lambda,\nu)$-nice partitioning $P$ with sets $B = \{B_1,\ldots,B_k\}$ the induced clustering of $C$ on $B$, i.e., $C|_B = \{B_1,\ldots,B_k\}$. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithm}


\noindent {\bf Goal}: Gievn the set $\mathcal{X}$ and the value $k$, our goal is to design an algorithm that do $k$-clustering $C=\{C_1,\ldots,C_k\}$ on set $\mathcal{X}$ such that  for any $(\lambda,\nu)$-nice partitioning $P$ with slusters $B_1,\ldots,B_k$ the induced clustering of $C$ on $\{B_1,\ldots,B_k\}$ is equal to $\{B_1,\ldots,B_k\}$


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Based on the knowledge of $\min |B_i|$}

% All algoritthms are polynomial in n and k

The algorithm gets as input $\mathcal{X}$ and the number of points in the smallest cluster $\min |B_i| = t$ (say). This algorithm works in two phases.

\noindent \textbf{Phase 1:}\\ Let $L$ denote the balls found so far. Initialize $L = \phi$.
\begin{itemize}
\item Let $B_S$ be smallest ball such that $c(B_S) \in \mathcal{X}$, $|B_S| \ge t$  and $|B_S \cap L | = \phi$.
\item $L = L \cup B_S$.
\item Delete all the points that are in $B_S$. That is, $\mathcal{X} = \mathcal{X}\setminus B_S$.
\item Repeat till such a ball $B_S$ exists.
\end{itemize}

\noindent \textbf{Phase 2:}\\ The first phase outputs a list of balls $L$. Let $L_C = c_1,\ldots,c_p$ be a list of centers of these balls. During the second phase, we use single linkage to cluster the centers $c_1,\ldots,c_p$. The output of this phase is a hierarchical tree and a list of possible nice clusterings. Let $D$ denote the $k$ clusters found so far. Let $E$ denote the list of clusterings found so far.
\begin{itemize}
\item Initialize $D = (c_1,\ldots.c_k)$ and $E = \phi$. Iterate over the list of centers $L_C$.
\item Given a new center $c_i$, $D' = D \cup c_i$ is a set of $k+1$ clusters. Merge the two closest centers in $D'$ to get a $k$-clustering. Assign $D$ to be that $k$-clustering. $E = E \cup D$.
\end{itemize}

\noindent In this way, we build a hierarchical clustering forest. This forest has $k$ trees corresponding to the $k$ different clusters we found. If the desired output is a tree rather than a forest, then 
\begin{itemize}
\item Use single linkage to merge the $k$-clusters found so far. 
\end{itemize}

We prove later that a pruning of this tree contains a clustering $C'$ such that $C'|_B = \{B_1,\ldots,B_k\}$. The algorithm also outputs a list $E$ of possible nice clusterings. We show that $|E| \in O(|\mathcal{X}|)$ and it contains a clustering $C'$ such that $C'|_B = \{B_1,\ldots,B_k\}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{No knowledge on $\min |B_i|$ }

Given the set $\mathcal{X}$,
we consider all the $l$ possible different distances between elements of the set $\mathcal{X}$. We know that there are $O(n^2)$ such distances. We sort them as $d_1<\ldots<d_l$. The algorithm works iteratively as following:


\begin{algorithm}
\begin{alg}
\label{NotKnown}

\item[] for $j=1$ to $l$
\item[] Let $L_j$ denote the set of balls found in $j^{th}$ iteration. Initially $L_j=\phi$;
\item[] set $d=d_j$;

\begin{itemize}

\item[] for $i=1$ to $k$

\begin{itemize}

\item[] Let $B_i$ be the densest ball of radius $2d$. Add $B_i$ to $L_j$.
\item[] Set $\mathcal{X}=\mathcal{X}\setminus B_{4d}(c(B_i))$. 

\end{itemize}

\end{itemize}

Output the list of clusters $L={L_1,\ldots,L_l}$.
\end{alg}
\caption{Alg. for unknown $\min{B_i}$}
\end{algorithm}

\noindent The algorithm outputs a list $L$ of possible nice clusterings. We sh ow that $|L| \in O(|\mathcal{X}|^2)$ and it contains a clustering $C'$ such that $C'|_B = \{B_1,\ldots,B_k\}$.

\begin{theorem}
Given a $()$-nice set $\mathcal{X}$,
\end{theorem}





\end{document}
